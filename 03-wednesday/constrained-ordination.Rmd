---
title: Constrained ordination
author: Gavin Simpson
date: May 29, 2024
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup-options, echo = FALSE, results = "hide", message = FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(cache = TRUE, dev = 'svg', echo = TRUE, message = FALSE, warning = FALSE, fig.height=6, fig.width = 1.777777*6)
```

# Abstract
```{r echo=FALSE,results="hide"}
options(width = 65, digits = 4)
library(mgcv)
```

# Canonical Correspondence Analysis
In this part of the practical you will use the `cca()` function from package **vegan** to perform a canonical correspondence analysis (CCA) of the diatom species data and the environmental data. Begin by loading **vegan** and reading in the data sets:

```{r echo=TRUE}
library("vegan")
url_env <- "https://bit.ly/pondsenv"
env <- read.csv(url(url_env))

url_diat <- "https://bit.ly/pondsdiat"
diat <- read.csv(url(url_diat))
```

The ponds are numbered numerically in the form X???, the species are encoded using DIATCODE and environmental variable codes should be reasonably self explanatory (except perhaps Secchi, which is the Secchi disk depth, a measure of water clarity):

```{r echo=TRUE}
rownames(diat)
names(diat)
names(env)
```

**vegan** has a nice formula interface, so it works in a similar way to the notation you used in the two regression practical classes. To fit a CCA model to the diatom and environmental data use the `cca()` function:

```{r echo=TRUE}
ponds.cca <- cca(diat ~ ., data = env)
ponds.cca
```

The formula means the diatom data matrix `diat` is modelled by everything in the environmental data matrix `env`. We use the data argument to inform R of where to look for the explanatory variables. The `.` is an **R** shortcut that saves you from having to type out the full formula.

**What are the values of $\lambda_1$ and $\lambda_2$, the eigenvalues for constrained axes one and two?**

**What is the total variance (inertia) in the diatom data?**

**What proportion of the total variance is explained by the environmental variables?**

**What proportion of the variance remains un-explained?**

The `scores()` method provides further, detailed results of the CCA:

```{r echo=TRUE,eval=FALSE}
wanted <- c("wa", "lc", "species", "bp", "cn")
scrs <- scores(ponds.cca, display = wanted)
scrs |> str()
scrs$biplot
```

**Why are there two sets of site scores (labelled "sites" and "constraints"?**

**Look at the biplot scores in the summary output. Suggest which variables are important on CCA axes 1 and on CCA axis 2?**

The `plot()` method is used to produce a triplot/biplot of the ordination results. Plot a triplot of the CCA of the `ponds` data.

```{r echo=TRUE,eval=TRUE}
plot(ponds.cca)
```

**Using the triplot, the biplot scores of the environmental variables and the ordination axes, interpret the axes in terms of environmental gradients.**

**Indicate which species are characteristic of particular types of water.**

## Comparison with unconstrained methods

Perform a CA of the ponds diatom data:

```{r echo=TRUE,eval=TRUE}
ponds.ca <- ca(diat)
ponds.ca
```

Refer to the handout on indirect ordination for hints and answer the following question:

**How does the result of the CCA compare to the results of the CA?**

**Plot the CA biplot and compare the configuration of sites in this biplot to the one shown in the CCA triplot. Does this suggest that our measured environmental variables explain the main floristic gradients in the diatom data?**

So far, you have used the default scaling (`scaling = "species"`) for the plots and summaries. Redraw the triplot using `scaling = "sites"`, to draw a triplot where the site scores are weighted averages of the species scores:

```{r echo=TRUE,eval=TRUE}
plot(ponds.cca, scaling = 1)
```

**What effect does the choice of scaling have on the ordination plots?**

## Interpreting the CCA results

There is a lot more that can be done to interpret the results of the CCA and explore relationships between the diatom species and the environmental variables, as well as determining model performance for the CCA itself.

## Outliers?
One useful diagnostic for the configuration is to identify outlier or "odd" sites or species. Plotting the Hill's $N_2$ values for both species and samples can help visualise outliers. We can produce biplots using $N_2$ values for species and sites easily in **R** using `renyi()` in **vegan**. First we calculate the $N_2$ values for sites and species:

```{r echo=TRUE,eval=TRUE}
diat.n2 <- renyi(t(diat), scales = 2, hill = TRUE)
ponds.n2 <- renyi(diat, scales = 2, hill = TRUE)
```

Then we use these values to scale the plotting symbol used to display the sites of the species and use `identify()` to label the outlier species/sites (remember to click on some species [red crosses] to label them and right click on the graph to finish). Firstly for the species:

```{r echo=TRUE,eval=TRUE}
sppN2 <- plot(ponds.cca, display = "species", type = "n")
points(ponds.cca, display = "species", pch = "+", col = "red", cex = 0.5)
symbols(scores(ponds.cca)$species, circles = diat.n2,
        add = TRUE, inches = 0.5)
text(ponds.cca, display = "bp", arrow.mul = 2,
     col = "blue", cex = 0.9)
identify(sppN2, what = "species", ps = 10)
```

&hellip;and for the sites:

```{r echo=TRUE,eval=TRUE}
siteN2 <- plot(ponds.cca, display = "sites", type = "n")
points(ponds.cca, display = "sites", pch = "+", col = "red", cex = 0.5)
symbols(scores(ponds.cca)$sites, circles = ponds.n2,
        add = TRUE, inches = 0.5)
text(ponds.cca, display = "bp", arrow.mul = 2,
     col = "blue", cex = 0.9)
identify(siteN2, what = "sites", ps = 10)
```

To help interpret these plots, we add the species/site labels to the species/site Hill's $N_2$ values and print them to the screen.

```{r eval=TRUE,echo=TRUE}
names(diat.n2) <- colnames(diat)
sort(diat.n2, decreasing = TRUE)
names(ponds.n2) <- rownames(diat)
sort(ponds.n2, decreasing = TRUE)
```

**Using the Hill's $N_2$ plots and the actual $N_2$ values for the sites and species, which species are abundant and which are rare in the Ponds diatom data set?**

**Which of the sites have low species diversity and which high diversity?**

### How significant are the constraints?

The CCA model we have built is a weighted, multivariate multiple regression and just as in regression, we want to achieve as parsimonious a model as possible, one that adequately describes the species environmental relationships without being overly complex. Whilst it is common for users to throw as many constraints as possible at a CCA this has the effect of _reducing_ the constraints on the ordination (it becomes more like the CA the more constraints you use) and of building an overly complex model that is over fitted to that particular data set. In this section you will look at some of the model building/selection tools available within **R** and **vegan**.

Firstly, we should look for redundant constraints&mdash;environmental variables that are highly corellated with each other are prime candidates for exclusion from the model. Produce a corellation matrix of the environmental data set and calculate the variance inflation factors for each variable.

```{r echo=TRUE,eval=FALSE}
cor(env) # output not shown in handout
```

```{r echo=TRUE,eval=TRUE}
vif.cca(ponds.cca)
```

**Suggest which variables might be redundant and therefore dropped from the CCA model?**

We should also check the significance of the full CCA model we have fit. This is done using the `anova()` function:

```{r echo=TRUE,eval=FALSE}
set.seed(42)
anova(ponds.cca)
```

Note that this uses random permutations hence we set a seed.

**Is the full model significant at the 0.01 level?**

Canoco also reports the species:environment correlation&mdash;the correlation between the sites scores that are weighted averages of the species scores and the site score that are linear combinations of the environmental data. Function `spenvcor()` calculates this correlation between the two sets of site scores.

```{r }
spenvcor(ponds.cca)
```

**Are there high correlations between the two sets of site scores?**

**What does this tell you about the relationships between the species and the environmental data?**

### Foward selection and backwards elimination
Whilst automated model building methods are not the panacea that many people think they are, they can be a useful aid when model building with lots of environmental variables.

The model selection tools available in **vegan** are different to those available in CANOCO, and are based on the concept of AIC, a fairly new concept for CCA as CCA is not based on concepts of deviance and log likelihoods (from which AIC was derived). Instead, features of the CCA results are converted into a deviance by calculating the Chi-square of the residual data matrix after fitting constraints (in RDA, deviance is taken to be the residual sum of squares instead). From here an AIC statistic can be calculated, the details of which are given in the reference quoted in the help page for `deviance.cca()` (type `?deviance.cca` at the **R** prompt to read this page if you so wish).

Before we begin, note that the author of **vegan**, Jari Oksanen, is not convinced about all aspects of this approach, and advocates checking the results manually &mdash; which is good advice seeing as you should not be relying on automated model selection tools anyway!

To begin, define a null model to which we will sequentially add variables in order of added importance:

```{r }
mod0 <- cca(diat ~ 1, data = env)
mod0
```

As you can see, this is an unconstrained model or a CA. Function `step.cca()` is used to _step_ forwards or backwards through a series of nested models adding or dropping an explanatory variable at each iteration ^[`step()` is a generic function and `step` methods can be written for different modelling functions. This means you only need to use the generic `step()` and **R** take care of finding and using the correct method for the object you are running `step()` on. Another example of a generic is `anova()`, which you used earlier &mdash; what you actually used was `anova.cca()`]. To use `step()` we need to define an upper and lower scope for the stepping to place over. We will use `mod0` as the lower scope and `ponds.cca` (the full model) as the upper scope when performing forward selection &mdash; this is reversed when performing backwards elimination.

```{r echo=TRUE,eval=FALSE}
mod <- step(ponds.cca, scope = list(lower = formula(mod0),
                         upper = formula(ponds.cca)), test = "perm")
```
```{r eval=TRUE,echo=FALSE}
mod <- step(ponds.cca, scope = list(lower = formula(mod0),
                         upper = formula(ponds.cca)), test = "perm", trace = FALSE)
```

You should have seen lots of output flash across the screen. At each stage, the effect of adding/dropping a variable is evaluated in terms of a permutation test. In the above example, we used both forwards and backwards elimination at each step.

Print out the record of the steps:

```{r }
mod$anova
```

We see that we started with the full model and calcium was dropped from the full model. Next Conductivity was dropped and so on, with TP being the last variable dropped. At no stage was a variable added back into the model. To view the final model simply type:

```{r }
mod
```

The final model contains two variables &mdash; secchi disk depth and maximum pond depth. Test this model and see how significant the effects of the constraints are:

```{r echo=TRUE,eval=FALSE}
anova(mod)
```

```{r echo=FALSE,eval=TRUE}
set.seed(123456)
anova(mod)
```

**Is this model better than full model?**

**How much of the total inertia is explained by the two constraints?**

Produce a triplot of this model:

```{r echo=TRUE,eval=TRUE}
plot(mod)
```

The triplot suggests that there is a strong outlier site in terms of maximum depth (Pond X113). We might wish to investigate how the CCA model might change if we deleted this observation. We delete this observation and build new null and full CCA models

```{r }
no.need <- which(rownames(diat) == "X113")
diat2 <- diat[-no.need, ]
env2 <- env[-no.need, ]
mod0 <- cca(diat2 ~ 1, data = env2)
cca.delete <- cca(diat2 ~ ., data = env2)
```

We can now retry the automatic stepping model selection and plot the resulting triplot:

```{r results="hide"}
mod.delete <- step(cca.delete, scope = list(lower = formula(mod0),
                   upper = formula(cca.delete)), test = "perm")
plot(mod.delete)
```

**How does this model compare to the model with MaxDepth and Secchi only?**

A further thing we should check is whether we get different models whether we do forward selection, backward elimination or both. The default for `step()` is to evaluate both forward and backward steps. If we wish to perform forward selection only, we need to tell **R** to start from the null model:

```{r results="hide"}
mod.fwd<- step(mod0, scope = list(lower = formula(mod0),
                   upper = formula(cca.delete)), test = "perm")
plot(mod.fwd)
```

**Which variables has forward selection chosen?**

This highlights one of the problems with automatic model building tools. As a description of the data, `mod.delete` seems a nicer plot, but it retains a number of environmental variables that are very correlated. Forward selection produces a model with a single environmental variable. So which to use? And therein lies the problem. There is no substitution for rolling up ones sleeves and getting involved in building and checking lots of candidate models.

As a starter, we could look at the significance of the terms in `mod.delete`:

```{r test1}
anova(mod.delete, by = "margin")
```

Here, the significance of terms are assessed marginally. A number of the environmental variables are not significant under this test. As a strategy for producing a parsimonious model, we might proceed by removing the variable that contributes the least here, NO<sub>3</sub>.

**As an exercise if you have time, try dropping out terms and rerun `anova` to try to produce a parsimonious model.**

## Step-wise selection using Adjusted $R^2$

A better way to do this for selection might be to include the adjusted $R^2$ in our evaluations of the changes to the models we make as we sequentially add or remove terms from the model. The function `ordiR2step()` does this for us, in which we not only add a variable if it significantly improves the model, but we also compare against the $R^2_{\text{adjusted}}$ of the model at the upper scope

```{r ordir2step-cca-delete}
mod.r2step <- ordiR2step(mod0, scope = formula(cca.delete))
mod.r2step
mod.r2step$anova
```

**Which terms have been retained in this model?**

**Does this differ from the previous step-wise selection?**

**Using `anova()` test the individual marginal effects of the terms retained in `mod.r2step`. Do all the terms have statistically significant marginal effects?**

## Partial CCA models
There are occasions where we might wish to fit a model to our species data after controlling for the effects of one or more environmental variables. These models are known as partial constrained ordinations &mdash; the effect of the one or more environmental variables are partialled out, and a CCA/RDA model is applied to explain the residual variation.

In **vegan** partial models are fitted using the `Condition()` function within the model formula describing the model you wish to fit. The `Condition()` function is used to _condition_ the model on the set of covariables and fit a model to the residuals of the conditioned model. Multiple variables can be included within `Condition()`, separated by a `+`. Partial models can also be used to evaluate the significance of adding a new variable to a model already containing one or more variables &mdash; partial out the existing variables and fit a model with the new variable of interest, using `anova()` to assess the effect of adding this new variable.

Say we were interested in investigating the effects of the hydrochemical variables on diatom distributions in the Ponds dataset, after controlling for the effects of `Maxdepth` and `Secchid`, we would fit this model in **R** like so:

```{r }
partial.mod <- cca(diat ~ . + Condition(Maxdepth + Secchid), data = env)
partial.mod
anova(partial.mod)
```

**Do the remaining environmental variables explain significant amounts of the variance in the species data after controlling for `Maxdepth` and `Secchid`?**

**How much of the variance is explained by the Conditional variables?**

**How much of the variance is explained by the constraints?**

**How much is left unexplained?**

Finally, plot a triplot for this model:

```{r echo=TRUE,eval=TRUE}
plot(partial.mod)
```
